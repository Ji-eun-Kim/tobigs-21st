{"cells":[{"cell_type":"markdown","metadata":{"id":"yclCebBQFn2I"},"source":["# CNNbasic Assignment#1\n","\n","\n","마크다운과 코드 속 `???` 를 채워주시면 됩니다!-!\n","\n","\n","# AlexNet\n","\n","모델 구조 사진과 논문 사이트입니다.\n","\n","- paper: http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf\n","\n","- dataset: http://image-net.org/challenges/LSVRC/2012/index#task\n","\n","- Model architecture\n","\n","![image.architecture1](attachment:image.png)\n","\n","![model_architecture2](https://t1.daumcdn.net/cfile/tistory/99FEB93C5C80B5192E)\n","\n","The second convolutional layer takes as input the (response-normalized\n","and pooled) output of the first convolutional layer and filters it with 256 kernels of size 5 × 5 × 48.\n","The third, fourth, and fifth convolutional layers are connected to one another without any intervening\n","pooling or normalization layers. The third convolutional layer has 384 kernels of size 3 × 3 ×\n","256 connected to the (normalized, pooled) outputs of the second convolutional layer. The fourth\n","convolutional layer has 384 kernels of size 3 × 3 × 192 , and the fifth convolutional layer has 256\n","kernels of size 3 × 3 × 192. The fully-connected layers have 4096 neurons each.\n","\n","\n","### Naive Version\n","CONV_1 - POOL_1 - CONV_2 - POOL_2 - CONV_3 - CONV_4 - CONV_5 - POOL_3 - FC1 - FC2 - FC3 (->SOFTMAX)\n","\n","### detailed\n","CONV_1(ReLU) - POOL_1 - CONV_2(ReLU) - POOL_2 - CONV_3(ReLU) - CONV_4(ReLU) - CONV_5(ReLU) - POOL_3 -(Flatten) FC1(ReLU) - FC2(ReLU) - FC3(->SOFTMAX)"]},{"cell_type":"markdown","metadata":{"id":"_pstPyOBdOg1"},"source":["* ImageNet의 train, valid 데이터셋 얻는 방법  \n","\n","출처: https://ndb796.tistory.com/471  \n","\n","```\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","# 데이터 전처리 및 로딩\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","train_dataset = datasets.ImageNet(root='path/to/imagenet', split='train', transform=transform)\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"OMWE4-56dOg2"},"source":["$$Output_{size} = \\frac{Input_{size} - Filter_{size} + 2\\cdot Padding}{Stride} +1$$"]},{"cell_type":"markdown","metadata":{"id":"exDZxL9QFn2L"},"source":["## Layer 1 is a Convolution Layer_1\n","\n","- **Input Image size**     224x224\n","\n","- **Number of filters**     96\n","\n","- **Filter size**     11x11\n","\n","- **Stride**     4\n","\n","- **Layer 1 Output**    round( (224 - 11 + 2 *0)/4 + 1) = 55"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"908NTid5dOg2","executionInfo":{"status":"ok","timestamp":1709642328761,"user_tz":-540,"elapsed":4853,"user":{"displayName":"박민지","userId":"15586126807640248748"}}},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torchsummary import summary as summary_\n","import torch.nn.init as init"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"XvKPu0jsdOg3","executionInfo":{"status":"ok","timestamp":1709642329809,"user_tz":-540,"elapsed":6,"user":{"displayName":"박민지","userId":"15586126807640248748"}}},"outputs":[],"source":["# Convolution + BatchNormalization + Relu 정의하기\n","def CBR2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=True):\n","    layers = []\n","    layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n","                            kernel_size=kernel_size, stride=stride, padding=padding,\n","                            bias=bias)]\n","    layers += [nn.BatchNorm2d(num_features=out_channels)]\n","    layers += [nn.ReLU()]\n","\n","    cbr = nn.Sequential(*layers)\n","\n","    return cbr"]},{"cell_type":"code","source":["def fc(input_size_fc, output_size_fc):\n","    layers = []\n","    layers += [nn.Linear(input_size_fc, output_size_fc)]\n","    layers += [nn.Dropout()]\n","    layers += [nn.ReLU()]\n","\n","    fc = nn.Sequential(*layers)\n","\n","    return fc"],"metadata":{"id":"GtFGnz-XsQiL","executionInfo":{"status":"ok","timestamp":1709643542835,"user_tz":-540,"elapsed":10,"user":{"displayName":"박민지","userId":"15586126807640248748"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","execution_count":6,"metadata":{"id":"FnFf4tcbdOg3","executionInfo":{"status":"ok","timestamp":1709642338093,"user_tz":-540,"elapsed":15,"user":{"displayName":"박민지","userId":"15586126807640248748"}}},"outputs":[],"source":["## TODO ##\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Conv_1 = CBR2d(in_channels=3, out_channels=96,\n","                                 kernel_size=11, stride=4, padding=0,\n","                                 bias=True)"]},{"cell_type":"code","source":["Conv_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsR9Iuwhn6Wd","executionInfo":{"status":"ok","timestamp":1709642340362,"user_tz":-540,"elapsed":556,"user":{"displayName":"박민지","userId":"15586126807640248748"}},"outputId":"84d1003e-6de6-4834-880c-5dcb51c00ff1"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","  (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (2): ReLU()\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"4pGeCQs6dOg3"},"source":["$$ Output_{size} = round(\\frac{Input_{size} - Pooling_{size}}{Stride} + 1 )$$"]},{"cell_type":"markdown","metadata":{"id":"XvlIbO-uFn2V"},"source":["\n","- Stride (스트라이드): 필터(커널)가 입력 데이터를 얼마나 건너뛰며 이동할지를 결정함. 예로, Stride가 1이면 한 칸씩 이동하고, Stride가 2이면 두 칸씩 이동을 의미. 예를 들어, 스트라이드가 2인 경우, 필터는 입력 데이터에서 2칸씩 이동하면서 연산을 수행함.  \n","\n","- Kernel Size (커널 크기): 필터(커널)의 크기를 의미하며, 커널은 입력 데이터에 적용되어 특징을 추출하는 역할을 함. 커널 크기가 3x3이라면 3x3 크기의 작은 윈도우로 입력 데이터를 스캔하여 특징을 추출함을 의미함.  \n","\n","\n","## Layer 2 is a Max Pooling_1 Followed by Convolution_1\n","\n","- **Input**     55\n","\n","- **Max pooling**     1\n","\n","- **Pooling size** (overlapping)      3\n","\n","    * overlapping 중첩되어서 지나감\n","\n","- **Stride**     2\n","\n","- **Layer 2 Output**     round( (55-3) / 2 +1 ) = 27\n","    \n","    * 차원은 변함 없음"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"dy5yYADMdOg3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709642349616,"user_tz":-540,"elapsed":427,"user":{"displayName":"박민지","userId":"15586126807640248748"}},"outputId":"2c933004-98d8-450c-cb89-d641c1ec6981"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)"]},"metadata":{},"execution_count":8}],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Max_pool_1 = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n","Max_pool_1"]},{"cell_type":"markdown","metadata":{"id":"r70OGeViFn2Z"},"source":["## Layer 3 is a Convolution Layer_2\n","\n","- **Input**     27\n","\n","- **Number of filters**     96\n","\n","- **Filter size**     5x5\n","\n","- **Stride**     1\n","\n","- **padding**     2\n","\n","- **Layer 3 Output**    round( (27 - 5 + 2 *2)/1 + 1) =   27"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u8dygslDdOg4"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Conv_2 = CBR2d(in_channels=96, out_channels=256,\n","                                 kernel_size=5, stride=1, padding=2,\n","                                 bias=True)\n","Conv_2"]},{"cell_type":"markdown","metadata":{"id":"DQZhwY4eFn2e"},"source":["## Layer 4 is a Max Pooling_2 Followed by Convolution_2\n","\n","- **Input**     27\n","\n","- **Max pooling**    1\n","\n","- **Pooling size**(overlapping)     3\n","\n","- **Stride**     2\n","\n","- **Layer 4 Output**     round( (27-3) / 2 +1 ) =  13"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jl7551ExdOg4"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Max_pool_2 =  nn.MaxPool2d(kernel_size=3, stride=2)\n","Max_pool_2"]},{"cell_type":"markdown","metadata":{"id":"xPm4PRFAFn2i"},"source":["## Layer 5 is a Convolution Layer_3\n","\n","- **Input**     13\n","\n","- **Number of filters**     384\n","\n","- **Filter size**     3\n","\n","- **Stride**     1\n","\n","- **padding**    1\n","\n","- **Layer 5 Output**  round((13-3 +2*1 )/1 +1) =  13\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yQFGiPOKdOg4"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Conv_3 = CBR2d(in_channels=256, out_channels=384,\n","                                 kernel_size=3, stride=1, padding=1,\n","                                 bias=True)\n","Conv_3"]},{"cell_type":"markdown","metadata":{"id":"Yv57b2vxFn2o"},"source":["## Layer 6 is  a Convolution Layer_4\n","\n","- **Input**     13\n","\n","- **Number of filters**     384\n","\n","- **Filter size**     3\n","\n","- **Stride**     1\n","\n","- **padding**     1\n","\n","- **Layer 6 Output**  round((13-3+2*1)/1+1) = 13"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lJxbMjKWdOg4"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Conv_4 = CBR2d(in_channels=384, out_channels=384,\n","                                 kernel_size=3, stride=1, padding=1,\n","                                 bias=True)\n","Conv_4"]},{"cell_type":"markdown","metadata":{"id":"NiQL84J_Fn2s"},"source":["## Layer 7 is a Convolution Layer_5\n","\n","- **Input**     13\n","\n","- **Number of filters**     256\n","\n","- **Filter size**     3\n","\n","- **Stride**     1\n","\n","- **padding**     1\n","\n","- **Layer 7 Output**  round((13-3+2*1)/1+1) = 13"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tAszz0mFdOg5"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Conv_5 = CBR2d(in_channels=384, out_channels=256,\n","                                 kernel_size=3, stride=1, padding=1,\n","                                 bias=True)\n","Conv_5"]},{"cell_type":"markdown","metadata":{"id":"WSTe-0IxFn2w"},"source":["## Layer 8 is a Max Pooling_3 Followed by Convolution_5\n","\n","- **Input**     13\n","\n","- **Max pooling**     1  \n","\n","- **Pooling size**(overlapping)     3\n","\n","- **Stride**     2\n","\n","- **Layer 8 Output**   round( (13-3)/2 +1) =  6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wjajD4AkdOg5"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","Max_pool_3 = nn.MaxPool2d(kernel_size=3, stride=2)\n","Max_pool_3"]},{"cell_type":"markdown","metadata":{"id":"798N3vBYFn21"},"source":["## Layer 9 is a Fully_Connected layer_1\n","\n","- **input**     6x6x256\n","\n","- **flatten**     9216\n","\n","- **output size**     4096\n","\n","- **N** Number of input data     9216"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"7JvB3BLxdOg5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709643612368,"user_tz":-540,"elapsed":1390,"user":{"displayName":"박민지","userId":"15586126807640248748"}},"outputId":"dd14afcb-952b-4007-a227-b4da34323285"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sequential(\n","  (0): Linear(in_features=9216, out_features=4096, bias=True)\n","  (1): Dropout(p=0.5, inplace=False)\n","  (2): ReLU()\n",")"]},"metadata":{},"execution_count":13}],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","FC1 = fc(6*6*256, 4096)\n","FC1"]},{"cell_type":"markdown","metadata":{"id":"kIfvpHPTFn25"},"source":["## Layer 10 is a Fully_Connected layer_2\n","\n","- **input**     4096\n","\n","- **output size**     4096\n","\n","- **N** Number of input data =      4096"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vz2TaQuSdOg5"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","FC2 = fc(4096,4096)\n","FC2"]},{"cell_type":"markdown","metadata":{"id":"N8TaZQTBFn29"},"source":["## Layer 11 is a Fully_Connected layer_3\n","\n","- **input**     4096\n","\n","- **output size**     1000\n","\n","- **N** Number of input data =      4096\n","\n","- **Num_classes** Number of labels =      1000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"URtSrZ0XdOg6"},"outputs":[],"source":["## TODO\n","\n","######################################################\n","#  Calculate the number of parameters in this layer  #\n","######################################################\n","\n","FC3 = fc(4096,1000)\n","\n","FC3"]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","# 모델 출력에 softmax를 적용한 후 손실을 계산하는 방법\n","'''loss_with_softmax = nn.CrossEntropyLoss()(F.softmax(FC3, dim=1), labels) #labels: validation of image'''"],"metadata":{"id":"uI_X3dEcugJI"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":0}