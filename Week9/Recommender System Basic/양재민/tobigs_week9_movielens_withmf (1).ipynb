{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9주차 recsys basic 과제: Q1, Q2에있는 빈칸을 채워주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens data 탐방하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "\n",
    "#다양한 hyperparameter를 조절하기 위한 argparser\n",
    "argparser = argparse.ArgumentParser()\n",
    "argparser.add_argument('--latent_dim', type=int, default=10)\n",
    "argparser.add_argument('--batch_size', type=int, default=500)\n",
    "args = argparser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 이건 토치용입니다.\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MlDataLoader(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무비렌즈 데이터 불러주는  class: ml100k\n",
    "ML100k 클래스에서 data_path만 여러분이 u.data를 불러올 수 있는 경로로 바꿔주세요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /home/yang/.conda/envs/test/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.3.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.3.0-py3-none-any.whl (17 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# traintest split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from src.preprocess.mldataloader import MlDataLoader\n",
    "\n",
    "\n",
    "class ML100k():\n",
    "\n",
    "    def __init__(self,args) -> None:\n",
    "        self.args=args\n",
    "        self.call_data(args)\n",
    "        pass\n",
    "\n",
    "    def call_data(self, args) -> None:\n",
    "        self.args = args\n",
    "        data_path=\"../u.data\" #이부분을 다운받은 데이터를 코랩에서 실행할 수 잇도록 바꿔주세요\n",
    "\n",
    "        self.data= pd.read_csv(data_path, sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "        self.num_users = self.data.user.nunique()\n",
    "        self.num_items = self.data.item.nunique()\n",
    "        self.num_ratings = len(self.data)    \n",
    "\n",
    "        # user, item index를 0부터 시작하도록 변경-. nn.Embedding에서 index가 0부터 시작하므로 1을 빼줍니다.\n",
    "        self.data.user = self.data.user -1\n",
    "        self.data.item = self.data.item -1\n",
    "        \n",
    "        \n",
    "        self.x = self.data[['user', 'item']].values\n",
    "        self.y= self.data.rating.values\n",
    "\n",
    "        # split data into train and test\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    def get_dataframe(self):\n",
    "        # sort dataframe by user\n",
    "        return self.data[['user', 'item','rating']]\n",
    "    \n",
    "        \n",
    "    def load_torch_data(self):\n",
    "\n",
    "        # convert x to integer, y to floattenser\n",
    "        self.x_train = torch.tensor(self.x_train, dtype=torch.long)\n",
    "        self.y_train = torch.tensor(self.y_train, dtype=torch.float)\n",
    "        self.x_test = torch.tensor(self.x_test, dtype=torch.long)\n",
    "        self.y_test = torch.tensor(self.y_test, dtype=torch.float)\n",
    "        \n",
    "\n",
    "        train_dataset = MlDataLoader(self.x_train, self.y_train)\n",
    "        test_dataset = MlDataLoader(self.x_test, self.y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.args.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.args.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k=ML100k(args)\n",
    "dataframe=ml100k.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>879</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>715</td>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>275</td>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>12</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>11</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating\n",
       "0       195   241       3\n",
       "1       185   301       3\n",
       "2        21   376       1\n",
       "3       243    50       2\n",
       "4       165   345       1\n",
       "...     ...   ...     ...\n",
       "99995   879   475       3\n",
       "99996   715   203       5\n",
       "99997   275  1089       1\n",
       "99998    12   224       2\n",
       "99999    11   202       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe# 아래와 같이 user, item, rating으로 이루어진 데이터프레임이 나오게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Q1 : 해당 데이터 프레임을 통해서 각각의 유저가 item들의 점수를 어떻게 매겼는지를 나타내는 user-item matrix(rating matrix)를 만들어 주세요!!\n",
    "이 때 유저가 시청하지 않은 데이터는 -1로 처리해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item  0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
       "user                                                              ...         \n",
       "0        5     3     4     3     3     5     4     1     5     3  ...    -1   \n",
       "1        4    -1    -1    -1    -1    -1    -1    -1    -1     2  ...    -1   \n",
       "2       -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "3       -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "4        4     3    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "938     -1    -1    -1    -1    -1    -1    -1    -1     5    -1  ...    -1   \n",
       "939     -1    -1    -1     2    -1    -1     4     5     3    -1  ...    -1   \n",
       "940      5    -1    -1    -1    -1    -1     4    -1    -1    -1  ...    -1   \n",
       "941     -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "942     -1     5    -1    -1    -1    -1    -1    -1     3    -1  ...    -1   \n",
       "\n",
       "item  1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
       "user                                                        \n",
       "0       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "1       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "2       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "3       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "4       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "938     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "939     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "940     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "941     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "942     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 코드를 작성해주세요\n",
    "rating_matrix=dataframe.pivot_table(index='user',columns='item',values='rating',fill_value=-1)\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1로 채워진 부분들을 채워주기 위해서 matrix factorization을 해봅시다\n",
    "이때 torch를 활용해서 sgd기반의 방법으로 user embedding과 item embedding을 훈련시켜 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 ml100k 클래스에서 torch dataloader를 불러오는 함수를 호출하여 데이터로더 형태의 train_loader, test_loader를 불러옵니다.\n",
    "train_loader, test_loader=ml100k.load_torch_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Matrix factorization model을 구현해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, args ,num_users,num_items) -> None:\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.user_embedding = nn.Embedding(self.num_users, self.latent_dim)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, self.latent_dim)\n",
    "        #self.dropout = nn.Dropout(p=args.dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x) -> None:\n",
    "        # x: (batch_size, 2) : index 0:user, index 1:item\n",
    "        user = x[:, 0]\n",
    "        item = x[:, 1]\n",
    "        user = self.user_embedding(user)\n",
    "        #user shape: (batch_size, latent_dim) 우리가 원하는 유저가 표현된 latent_dim 차원의 벡터\n",
    "        item = self.item_embedding(item) \n",
    "        #item shape: (batch_size, latent_dim) 우리가 원하는 아이템이 표현된 latent_dim 차원의 벡터\n",
    "\n",
    "        out = torch.sum(user * item, dim=1) # 내적을 통해서 구하기,\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐 EMbedding이 어떻게 동작하는지 확인한번만 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uemb_temp=nn.Embedding(ml100k.num_users, args.latent_dim)\n",
    "iembe_temp=nn.Embedding(ml100k.num_items, args.latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([943, 10])\n",
      "torch.Size([1682, 10])\n"
     ]
    }
   ],
   "source": [
    "print(uemb_temp.weight.shape)\n",
    "print(iembe_temp.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.4641,  0.3351, -1.2466,  ..., -0.9561, -0.4217,  1.0331],\n",
       "        [-0.3160, -0.6751, -0.5141,  ...,  1.3306,  1.2104,  1.7352],\n",
       "        [ 0.5514, -1.9808, -1.9849,  ..., -0.0810,  1.1391, -1.6611],\n",
       "        ...,\n",
       "        [ 1.2441,  0.0638,  1.0465,  ...,  0.9198, -1.2126,  0.1097],\n",
       "        [-2.1287,  0.5005, -0.3823,  ...,  1.4006, -0.8987, -1.6914],\n",
       "        [ 1.1890, -0.2972,  0.1160,  ...,  0.1206, -0.1253,  1.3920]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uemb_temp.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.4601,  0.8592, -0.6129,  ..., -1.5253, -0.6080, -1.2354],\n",
       "        [ 0.3708,  0.6575, -0.1598,  ..., -1.2372, -0.0279,  0.5040],\n",
       "        [-0.3926, -0.4646,  1.0980,  ..., -0.2687,  1.7898,  0.6122],\n",
       "        ...,\n",
       "        [-1.5988, -0.3890,  1.4416,  ...,  0.0285,  1.8501, -0.4362],\n",
       "        [ 0.4506, -1.1946, -0.8430,  ..., -0.5151,  0.2456,  0.0662],\n",
       "        [ 0.9731,  0.5596, -0.3561,  ..., -0.2391, -0.3338, -0.2886]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iembe_temp.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 nn.Embedding을 통해서 유저, 아이템에 대한 embedding matrix를 저장하고 훈련시킬 수 잇는 네트워크라고 보시면 됩니다.(자연어에서 사용되는 nn.embedding과 같습니다.`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 이제 모델을 훈련시켜봅시다. 엄밀히 훈련시키려면 regularization,earlystopping등의 장치가 추가적으로 필요하지만, 돌아가는거만 확인하기 위해서 최대한 간단한 형태로 구현했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    \n",
    "    def train(self, data, test_data, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for (x,y) in data:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = self.criterion(output, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # print test loss\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for (x,y) in test_data:\n",
    "                    x = x.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "                    output = self.model(x)\n",
    "                    test_loss += self.criterion(output, y)\n",
    "\n",
    "                #normalize test loss\n",
    "            test_loss /= len(test_data)\n",
    "            print(f\"Epoch {epoch} train loss: {loss.item()} test loss: {test_loss.item()}\")\n",
    "\n",
    "        print(\"Training finished\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Epoch 0 train loss: 3.3060355186462402 test loss: 2.6313536167144775\n",
      "Epoch 1 train loss: 1.0687007904052734 test loss: 1.3431037664413452\n",
      "Epoch 2 train loss: 1.0125938653945923 test loss: 1.250959038734436\n",
      "Epoch 3 train loss: 1.0015122890472412 test loss: 1.226389765739441\n",
      "Epoch 4 train loss: 0.8630713820457458 test loss: 1.222793698310852\n",
      "Epoch 5 train loss: 0.9900162220001221 test loss: 1.2172927856445312\n",
      "Epoch 6 train loss: 0.8205846548080444 test loss: 1.2488025426864624\n",
      "Epoch 7 train loss: 0.8373615741729736 test loss: 1.2248910665512085\n",
      "Epoch 8 train loss: 0.8997617363929749 test loss: 1.2664873600006104\n",
      "Epoch 9 train loss: 0.9109413623809814 test loss: 1.2566653490066528\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# model, optimizer, criterion, device를 정의합니다.\n",
    "model = MF(args, ml100k.num_users, ml100k.num_items)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.05)\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# trainer를 정의합니다.\n",
    "trainer = Trainer(model, optimizer, criterion, device)\n",
    "trainer.train(train_loader, test_loader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아까 빈칸이었던 user-item matrix를 채워봅시다!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix=dataframe.pivot(index='user', columns='item', values='rating').fillna(-1) #pandas로 하면 너무느려져서 numpy로 바구고 진행합시다\n",
    "user_item_matrix=user_item_matrix.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cpu() #모델을 cpu로 바꿔주고\n",
    "# 훈련된 embedding을 numpy로 바꿔줍니다.\n",
    "np_userembedding=model.user_embedding.weight.detach().numpy() \n",
    "np_itemembedding=model.item_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., -1., -1., -1.],\n",
       "       [ 4., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [ 5., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1.,  5., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. 아래 코드를 완성해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드를 완성해주세요\n",
    "for i in range(ml100k.num_users):\n",
    "    for j in range(ml100k.num_items):\n",
    "        if user_item_matrix[i,j]==-1:\n",
    "            user_item_matrix[i,j]= np.dot(np_userembedding[i],np_itemembedding[j])  # 물음표를 채워주세요! , HInt  : 내적 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.00000000e+00,  3.00000000e+00,  4.00000000e+00, ...,\n",
       "        -4.09730375e-01,  1.59113574e+00, -3.68152523e+00],\n",
       "       [ 4.00000000e+00,  3.11689663e+00,  2.87994027e+00, ...,\n",
       "         1.17439032e-03,  2.50048184e+00, -6.50377750e+00],\n",
       "       [ 3.35102296e+00,  2.32496309e+00,  1.18042397e+00, ...,\n",
       "        -4.65569645e-02,  1.84650517e+00, -3.89335322e+00],\n",
       "       ...,\n",
       "       [ 5.00000000e+00,  3.39868021e+00,  3.03889227e+00, ...,\n",
       "         1.04722691e+00,  1.56511140e+00, -4.15220976e+00],\n",
       "       [ 5.00220537e+00,  4.24875593e+00,  3.23860002e+00, ...,\n",
       "        -3.69506091e-01,  3.66063595e+00, -3.79572558e+00],\n",
       "       [ 5.05492067e+00,  5.00000000e+00,  4.14451599e+00, ...,\n",
       "        -3.20231289e-01,  3.44614840e+00, -4.00939226e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가로....\n",
    "결과를 보면 범위가 -3 에서  +5보다 큰 값도 나왔는데, 일반적으로는 0.5~5 사이로 normalization을 시켜주는 것 같습니다. 이건 생략하겠습니다 ㅎㅎ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
