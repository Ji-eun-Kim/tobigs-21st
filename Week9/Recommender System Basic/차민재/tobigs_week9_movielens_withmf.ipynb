{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9주차 recsys basic 과제: Q1, Q2에있는 빈칸을 채워주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movielens data 탐방하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "#from src.preprocess.ml100k import ML100k\n",
    "#from src.models.mf import MF\n",
    "#from src.utils.trainer import Trainer\n",
    "import torch\n",
    "\n",
    "#다양한 hyperparameter를 조절하기 위한 argparser\n",
    "argparser = argparse.ArgumentParser()\n",
    "argparser.add_argument('--latent_dim', type=int, default=10)\n",
    "argparser.add_argument('--batch_size', type=int, default=500)\n",
    "args = argparser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 이건 토치용입니다.\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class MlDataLoader(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 무비렌즈 데이터 불러주는  class: ml100k\n",
    "ML100k 클래스에서 data_path만 여러분이 u.data를 불러올 수 있는 경로로 바꿔주세요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# traintest split\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from src.preprocess.mldataloader import MlDataLoader\n",
    "\n",
    "\n",
    "class ML100k():\n",
    "\n",
    "    def __init__(self,args) -> None:\n",
    "        self.args=args\n",
    "        self.call_data(args)\n",
    "        pass\n",
    "\n",
    "    def call_data(self, args) -> None:\n",
    "        self.args = args\n",
    "        data_path=\"u.data\" #이부분을 다운받은 데이터를 코랩에서 실행할 수 잇도록 바꿔주세요\n",
    "\n",
    "        self.data= pd.read_csv(data_path, sep='\\t', header=None, names=['user', 'item', 'rating', 'timestamp'])\n",
    "        self.num_users = self.data.user.nunique()\n",
    "        self.num_items = self.data.item.nunique()\n",
    "        self.num_ratings = len(self.data)    \n",
    "\n",
    "        # user, item index를 0부터 시작하도록 변경-. nn.Embedding에서 index가 0부터 시작하므로 1을 빼줍니다.\n",
    "        self.data.user = self.data.user -1\n",
    "        self.data.item = self.data.item -1\n",
    "        \n",
    "        \n",
    "        self.x = self.data[['user', 'item']].values\n",
    "        self.y= self.data.rating.values\n",
    "\n",
    "        # split data into train and test\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x, self.y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    def get_dataframe(self):\n",
    "        # sort dataframe by user\n",
    "        return self.data[['user', 'item','rating']]\n",
    "    \n",
    "        \n",
    "    def load_torch_data(self):\n",
    "\n",
    "        # convert x to integer, y to floattenser\n",
    "        self.x_train = torch.tensor(self.x_train, dtype=torch.long)\n",
    "        self.y_train = torch.tensor(self.y_train, dtype=torch.float)\n",
    "        self.x_test = torch.tensor(self.x_test, dtype=torch.long)\n",
    "        self.y_test = torch.tensor(self.y_test, dtype=torch.float)\n",
    "        \n",
    "\n",
    "        train_dataset = MlDataLoader(self.x_train, self.y_train)\n",
    "        test_dataset = MlDataLoader(self.x_test, self.y_test)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=self.args.batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=self.args.batch_size, shuffle=False)\n",
    "\n",
    "        return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml100k=ML100k(args)\n",
    "dataframe=ml100k.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195</td>\n",
       "      <td>241</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>301</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>376</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>243</td>\n",
       "      <td>50</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165</td>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>879</td>\n",
       "      <td>475</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>715</td>\n",
       "      <td>203</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>275</td>\n",
       "      <td>1089</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>12</td>\n",
       "      <td>224</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>11</td>\n",
       "      <td>202</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user  item  rating\n",
       "0       195   241       3\n",
       "1       185   301       3\n",
       "2        21   376       1\n",
       "3       243    50       2\n",
       "4       165   345       1\n",
       "...     ...   ...     ...\n",
       "99995   879   475       3\n",
       "99996   715   203       5\n",
       "99997   275  1089       1\n",
       "99998    12   224       2\n",
       "99999    11   202       3\n",
       "\n",
       "[100000 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe# 아래와 같이 user, item, rating으로 이루어진 데이터프레임이 나오게 됩니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Q1 : 해당 데이터 프레임을 통해서 각각의 유저가 item들의 점수를 어떻게 매겼는지를 나타내는 user-item matrix(rating matrix)를 만들어 주세요!!\n",
    "이 때 유저가 시청하지 않은 데이터는 -1로 처리해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1672</th>\n",
       "      <th>1673</th>\n",
       "      <th>1674</th>\n",
       "      <th>1675</th>\n",
       "      <th>1676</th>\n",
       "      <th>1677</th>\n",
       "      <th>1678</th>\n",
       "      <th>1679</th>\n",
       "      <th>1680</th>\n",
       "      <th>1681</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>942</th>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>943 rows × 1682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item  0     1     2     3     4     5     6     7     8     9     ...  1672  \\\n",
       "user                                                              ...         \n",
       "0        5     3     4     3     3     5     4     1     5     3  ...    -1   \n",
       "1        4    -1    -1    -1    -1    -1    -1    -1    -1     2  ...    -1   \n",
       "2       -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "3       -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "4        4     3    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "938     -1    -1    -1    -1    -1    -1    -1    -1     5    -1  ...    -1   \n",
       "939     -1    -1    -1     2    -1    -1     4     5     3    -1  ...    -1   \n",
       "940      5    -1    -1    -1    -1    -1     4    -1    -1    -1  ...    -1   \n",
       "941     -1    -1    -1    -1    -1    -1    -1    -1    -1    -1  ...    -1   \n",
       "942     -1     5    -1    -1    -1    -1    -1    -1     3    -1  ...    -1   \n",
       "\n",
       "item  1673  1674  1675  1676  1677  1678  1679  1680  1681  \n",
       "user                                                        \n",
       "0       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "1       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "2       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "3       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "4       -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "...    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "938     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "939     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "940     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "941     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "942     -1    -1    -1    -1    -1    -1    -1    -1    -1  \n",
       "\n",
       "[943 rows x 1682 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 코드를 작성해주세요\n",
    "rating_matrix= dataframe.pivot_table(index='user', columns='item', values='rating', fill_value = -1)\n",
    "rating_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -1로 채워진 부분들을 채워주기 위해서 matrix factorization을 해봅시다\n",
    "이때 torch를 활용해서 sgd기반의 방법으로 user embedding과 item embedding을 훈련시켜 보겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에 ml100k 클래스에서 torch dataloader를 불러오는 함수를 호출하여 데이터로더 형태의 train_loader, test_loader를 불러옵니다.\n",
    "train_loader, test_loader=ml100k.load_torch_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 Matrix factorization model을 구현해봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MF(nn.Module):\n",
    "\n",
    "    def __init__(self, args ,num_users,num_items) -> None:\n",
    "        super().__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = args.latent_dim\n",
    "        self.user_embedding = nn.Embedding(self.num_users, self.latent_dim)\n",
    "        self.item_embedding = nn.Embedding(self.num_items, self.latent_dim)\n",
    "        #self.dropout = nn.Dropout(p=args.dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x) -> None:\n",
    "        # x: (batch_size, 2) : index 0:user, index 1:item\n",
    "        user = x[:, 0]\n",
    "        item = x[:, 1]\n",
    "        user = self.user_embedding(user)\n",
    "        #user shape: (batch_size, latent_dim) 우리가 원하는 유저가 표현된 latent_dim 차원의 벡터\n",
    "        item = self.item_embedding(item) \n",
    "        #item shape: (batch_size, latent_dim) 우리가 원하는 아이템이 표현된 latent_dim 차원의 벡터\n",
    "\n",
    "        out = torch.sum(user * item, dim=1) # 내적을 통해서 구하기,\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 잠깐 EMbedding이 어떻게 동작하는지 확인한번만 해봅시다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uemb_temp=nn.Embedding(ml100k.num_users, args.latent_dim)\n",
    "iembe_temp=nn.Embedding(ml100k.num_items, args.latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([943, 10])\n",
      "torch.Size([1682, 10])\n"
     ]
    }
   ],
   "source": [
    "print(uemb_temp.weight.shape)\n",
    "print(iembe_temp.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.8042, -0.3208,  1.4206,  ..., -1.2483,  0.1321,  0.8689],\n",
       "        [ 0.7075, -0.5005,  0.3649,  ...,  0.0358, -1.7249, -0.0278],\n",
       "        [-0.0316,  0.9888, -0.7697,  ...,  0.1020,  0.1714,  0.5184],\n",
       "        ...,\n",
       "        [-0.7199,  0.5026,  0.8080,  ..., -0.5457, -0.1635,  1.7938],\n",
       "        [-0.0526, -0.5657, -1.2019,  ..., -1.2979, -0.4574, -0.1056],\n",
       "        [ 0.0915, -0.1767, -1.2753,  ..., -1.4501,  0.2763,  0.6283]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uemb_temp.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.5585, -0.6795, -1.5973,  ...,  0.4787, -0.7449, -0.4927],\n",
       "        [-0.4263, -0.9501, -1.6837,  ..., -0.1856,  0.3762,  0.3171],\n",
       "        [-0.7972,  1.6544, -0.7199,  ..., -0.1688,  2.2113, -0.1794],\n",
       "        ...,\n",
       "        [-1.0121, -0.9687, -1.9403,  ..., -0.2935, -1.7082,  0.7849],\n",
       "        [ 0.0309, -0.3723,  0.0879,  ..., -0.3212,  0.4720,  0.6483],\n",
       "        [ 0.4394,  0.8156, -0.1883,  ..., -0.6379,  1.0238,  0.1153]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iembe_temp.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉 nn.Embedding을 통해서 유저, 아이템에 대한 embedding matrix를 저장하고 훈련시킬 수 잇는 네트워크라고 보시면 됩니다.(자연어에서 사용되는 nn.embedding과 같습니다.`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그럼 이제 모델을 훈련시켜봅시다. 엄밀히 훈련시키려면 regularization,earlystopping등의 장치가 추가적으로 필요하지만, 돌아가는거만 확인하기 위해서 최대한 간단한 형태로 구현했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Trainer():\n",
    "\n",
    "    def __init__(self, model, optimizer, criterion, device):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "\n",
    "    \n",
    "    def train(self, data, test_data, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for (x,y) in data:\n",
    "                x = x.to(self.device)\n",
    "                y = y.to(self.device)\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(x)\n",
    "                loss = self.criterion(output, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                # print test loss\n",
    "            test_loss = 0\n",
    "            with torch.no_grad():\n",
    "                for (x,y) in test_data:\n",
    "                    x = x.to(self.device)\n",
    "                    y = y.to(self.device)\n",
    "                    output = self.model(x)\n",
    "                    test_loss += self.criterion(output, y)\n",
    "\n",
    "                #normalize test loss\n",
    "            test_loss /= len(test_data)\n",
    "            print(f\"Epoch {epoch} train loss: {loss.item()} test loss: {test_loss.item()}\")\n",
    "\n",
    "        print(\"Training finished\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 2.231835126876831 test loss: 2.2291665077209473\n",
      "Epoch 1 train loss: 1.0771385431289673 test loss: 1.3018856048583984\n",
      "Epoch 2 train loss: 0.9141533970832825 test loss: 1.2118275165557861\n",
      "Epoch 3 train loss: 1.0443257093429565 test loss: 1.2005512714385986\n",
      "Epoch 4 train loss: 0.8976415395736694 test loss: 1.2110000848770142\n",
      "Epoch 5 train loss: 0.9367989897727966 test loss: 1.2324209213256836\n",
      "Epoch 6 train loss: 0.9026529788970947 test loss: 1.2581793069839478\n",
      "Epoch 7 train loss: 0.9538747668266296 test loss: 1.2524778842926025\n",
      "Epoch 8 train loss: 1.029626488685608 test loss: 1.2689944505691528\n",
      "Epoch 9 train loss: 1.0759207010269165 test loss: 1.2744567394256592\n",
      "Training finished\n"
     ]
    }
   ],
   "source": [
    "# model, optimizer, criterion, device를 정의합니다.\n",
    "model = MF(args, ml100k.num_users, ml100k.num_items)\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.05)\n",
    "criterion = nn.MSELoss()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# trainer를 정의합니다.\n",
    "trainer = Trainer(model, optimizer, criterion, device)\n",
    "trainer.train(train_loader, test_loader, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 아까 빈칸이었던 user-item matrix를 채워봅시다!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix=dataframe.pivot(index='user', columns='item', values='rating').fillna(-1) #pandas로 하면 너무느려져서 numpy로 바구고 진행합시다\n",
    "user_item_matrix=user_item_matrix.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=model.cpu() #모델을 cpu로 바꿔주고\n",
    "# 훈련된 embedding을 numpy로 바꿔줍니다.\n",
    "np_userembedding=model.user_embedding.weight.detach().numpy() \n",
    "np_itemembedding=model.item_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.,  3.,  4., ..., -1., -1., -1.],\n",
       "       [ 4., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [ 5., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1., -1., -1., ..., -1., -1., -1.],\n",
       "       [-1.,  5., -1., ..., -1., -1., -1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2. 아래 코드를 완성해주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 코드를 완성해주세요\n",
    "for i in range(ml100k.num_users):\n",
    "    for j in range(ml100k.num_items):\n",
    "        if user_item_matrix[i,j]==-1:\n",
    "            user_item_matrix[i,j]= np.dot(np_userembedding[i], np_itemembedding[j])\n",
    "            # 물음표를 채워주세요! , HInt  : 내적 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.        ,  3.        ,  4.        , ..., -0.3294259 ,\n",
       "         4.29086113, -1.62487245],\n",
       "       [ 4.        ,  3.63866878,  3.20243526, ..., -2.04249072,\n",
       "         2.33298612, -3.49111295],\n",
       "       [ 2.8631928 ,  3.34773207,  1.95396161, ..., -4.899189  ,\n",
       "         0.92023921, -3.92216325],\n",
       "       ...,\n",
       "       [ 5.        ,  2.89591432,  3.46464801, ..., -2.31008029,\n",
       "         2.41001153, -0.96046776],\n",
       "       [ 3.51249242,  3.34161353,  3.8506422 , ..., -2.09282088,\n",
       "         0.09802102, -1.43942297],\n",
       "       [ 3.77554607,  5.        ,  3.53221488, ...,  1.73840892,\n",
       "         1.92621434,  2.79784608]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 추가로....\n",
    "결과를 보면 범위가 -3 에서  +5보다 큰 값도 나왔는데, 일반적으로는 0.5~5 사이로 normalization을 시켜주는 것 같습니다. 이건 생략하겠습니다 ㅎㅎ.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
