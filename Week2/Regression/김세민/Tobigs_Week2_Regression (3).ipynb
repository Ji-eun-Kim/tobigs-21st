{"cells":[{"cell_type":"markdown","metadata":{"id":"fu39oBW0RVn5"},"source":["# [과제 3] 로지스틱 회귀분석\n","### - sklearn 패키지를 사용해 로지스틱 회귀분석을 진행해주세요.\n","### - 성능지표를 계산하고 이에 대해 해석해주세요.\n","### - 성능 개선을 시도해주세요. (어떠한 성능지표를 기준으로 개선을 시도했는지, 그 이유도 함께 적어주세요.)\n","### - 주석으로 설명 및 근거 자세하게 달아주시면 감사하겠습니다. :)"]},{"cell_type":"markdown","metadata":{"id":"8rN2SWezRVn_"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"Y7SYKNvQRVn_"},"source":["출처 : https://www.kaggle.com/mlg-ulb/creditcardfraud\n","\n","\n","* V1 ~ V28 : 비식별화 된 개인정보\n","* **Class** : Target 변수  \n","  - 1 : fraudulent transactions (사기)\n","  - 0 : otherwise"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Uvjw2fTCRVoA"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"znQit70ZRVoA"},"outputs":[],"source":["data = pd.read_csv(\"assignment3_creditcard.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"v98OeXW5RVoB","outputId":"42afeddc-07e6-4224-95ee-08b455f72475"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.848212</td>\n","      <td>2.384900</td>\n","      <td>0.379573</td>\n","      <td>1.048381</td>\n","      <td>-0.845070</td>\n","      <td>2.537837</td>\n","      <td>-4.542983</td>\n","      <td>-10.201458</td>\n","      <td>-1.504967</td>\n","      <td>-2.234167</td>\n","      <td>...</td>\n","      <td>2.585817</td>\n","      <td>-5.291690</td>\n","      <td>0.859364</td>\n","      <td>0.423231</td>\n","      <td>-0.506985</td>\n","      <td>1.020052</td>\n","      <td>-0.627751</td>\n","      <td>-0.017753</td>\n","      <td>0.280982</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.071805</td>\n","      <td>-0.477943</td>\n","      <td>-1.444444</td>\n","      <td>-0.548657</td>\n","      <td>0.010036</td>\n","      <td>-0.582242</td>\n","      <td>-0.042878</td>\n","      <td>-0.247160</td>\n","      <td>1.171923</td>\n","      <td>-0.342382</td>\n","      <td>...</td>\n","      <td>-0.077306</td>\n","      <td>0.042858</td>\n","      <td>0.390125</td>\n","      <td>0.041569</td>\n","      <td>0.598427</td>\n","      <td>0.098803</td>\n","      <td>0.979686</td>\n","      <td>-0.093244</td>\n","      <td>-0.065615</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.985294</td>\n","      <td>-2.747472</td>\n","      <td>1.194068</td>\n","      <td>-0.003036</td>\n","      <td>-1.151041</td>\n","      <td>-0.263559</td>\n","      <td>0.553500</td>\n","      <td>0.635600</td>\n","      <td>0.438545</td>\n","      <td>-1.806488</td>\n","      <td>...</td>\n","      <td>1.345776</td>\n","      <td>0.373760</td>\n","      <td>-0.385777</td>\n","      <td>1.197596</td>\n","      <td>0.407229</td>\n","      <td>0.008013</td>\n","      <td>0.762362</td>\n","      <td>-0.299024</td>\n","      <td>-0.303929</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.479452</td>\n","      <td>1.542874</td>\n","      <td>0.290895</td>\n","      <td>0.838142</td>\n","      <td>-0.529290</td>\n","      <td>-0.717661</td>\n","      <td>0.484516</td>\n","      <td>0.545092</td>\n","      <td>-0.780767</td>\n","      <td>0.324804</td>\n","      <td>...</td>\n","      <td>0.038397</td>\n","      <td>0.116771</td>\n","      <td>0.405560</td>\n","      <td>-0.116453</td>\n","      <td>0.541275</td>\n","      <td>-0.216665</td>\n","      <td>-0.415578</td>\n","      <td>0.027126</td>\n","      <td>-0.150347</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.281976</td>\n","      <td>-0.309699</td>\n","      <td>-2.162299</td>\n","      <td>-0.851514</td>\n","      <td>0.106167</td>\n","      <td>-1.483888</td>\n","      <td>1.930994</td>\n","      <td>-0.843049</td>\n","      <td>-1.249272</td>\n","      <td>1.079608</td>\n","      <td>...</td>\n","      <td>-0.875516</td>\n","      <td>-0.004199</td>\n","      <td>1.015108</td>\n","      <td>-0.026748</td>\n","      <td>0.077115</td>\n","      <td>-1.468822</td>\n","      <td>0.751700</td>\n","      <td>0.496732</td>\n","      <td>0.331001</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 29 columns</p>\n","</div>"],"text/plain":["         V1        V2        V3        V4        V5        V6        V7  \\\n","0 -1.848212  2.384900  0.379573  1.048381 -0.845070  2.537837 -4.542983   \n","1  2.071805 -0.477943 -1.444444 -0.548657  0.010036 -0.582242 -0.042878   \n","2 -2.985294 -2.747472  1.194068 -0.003036 -1.151041 -0.263559  0.553500   \n","3 -1.479452  1.542874  0.290895  0.838142 -0.529290 -0.717661  0.484516   \n","4 -0.281976 -0.309699 -2.162299 -0.851514  0.106167 -1.483888  1.930994   \n","\n","          V8        V9       V10  ...       V20       V21       V22       V23  \\\n","0 -10.201458 -1.504967 -2.234167  ...  2.585817 -5.291690  0.859364  0.423231   \n","1  -0.247160  1.171923 -0.342382  ... -0.077306  0.042858  0.390125  0.041569   \n","2   0.635600  0.438545 -1.806488  ...  1.345776  0.373760 -0.385777  1.197596   \n","3   0.545092 -0.780767  0.324804  ...  0.038397  0.116771  0.405560 -0.116453   \n","4  -0.843049 -1.249272  1.079608  ... -0.875516 -0.004199  1.015108 -0.026748   \n","\n","        V24       V25       V26       V27       V28  Class  \n","0 -0.506985  1.020052 -0.627751 -0.017753  0.280982      0  \n","1  0.598427  0.098803  0.979686 -0.093244 -0.065615      0  \n","2  0.407229  0.008013  0.762362 -0.299024 -0.303929      0  \n","3  0.541275 -0.216665 -0.415578  0.027126 -0.150347      0  \n","4  0.077115 -1.468822  0.751700  0.496732  0.331001      0  \n","\n","[5 rows x 29 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 99.88%\n","Confusion Matrix:\n","[[5688    0]\n"," [   7   41]]\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n","\n","\n","X = data.iloc[:,:-1]\n","y = data.Class\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 로지스틱 회귀 모델 생성 및 훈련\n","logreg_model = LogisticRegression()\n","logreg_model.fit(X_train, y_train)\n","\n","# 테스트 데이터에 대한 예측\n","y_pred = logreg_model.predict(X_test)\n","\n","# 정확도 평가\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy * 100:.2f}%')\n","\n","# 혼동 행렬(confusion matrix) 출력\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print('Confusion Matrix:')\n","print(conf_matrix)"]},{"cell_type":"markdown","metadata":{},"source":["Accuracy 값은 굉장히 높게 도출됨."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["0    28432\n","1      246\n","Name: Class, dtype: int64"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["data.Class.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["그러나 class 불균형이 심하기 때문에 accuracy로는 모델의 성능을 제대로 측정할 수 없음.\n","\n","보다 나은 성능지표를 찾기 위해 classification_report 함수를 활용"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      5688\n","           1       1.00      0.85      0.92        48\n","\n","    accuracy                           1.00      5736\n","   macro avg       1.00      0.93      0.96      5736\n","weighted avg       1.00      1.00      1.00      5736\n","\n"]}],"source":["# 분류 보고서 출력 (정밀도, 재현율, F1-score)\n","class_report = classification_report(y_test, y_pred)\n","print('Classification Report:')\n","print(class_report)"]},{"cell_type":"markdown","metadata":{},"source":["classification report에 명시된 평가지표를 통해 모델의 성능을 평가한 결과, 클래스 0에 대해서는 매우 높은 정확도를 보이고 있지만, 클래스 1에 대해서는 recall 값이 낮게 나타난다는 사실을 확인할 수 있음.\n","\n","이는 클래스 1이 클래스 0에 비해 더 적게 분포하고 있어서 발생하는 현상이기 때문에 실제 클래스 1인 경우를 더 잘 식별할 수 있도록 모델을 조정해야 함. (클래스 1에 대한 f1-score 값을 높여야 함)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["f1-score 기준 상위 5개 threshold 값\n","1위: threshold = 0.2779559118236473 / f1_score = 0.9565217391304348\n","2위: threshold = 0.2763527054108217 / f1_score = 0.9565217391304348\n","3위: threshold = 0.274749498997996 / f1_score = 0.9565217391304348\n","4위: threshold = 0.2731462925851703 / f1_score = 0.9565217391304348\n","5위: threshold = 0.2715430861723447 / f1_score = 0.9565217391304348\n"]}],"source":["# 테스트 데이터에 대한 예측 확률\n","y_prob = logreg_model.predict_proba(X_test)[:, 1]\n","\n","# 최적의 threshold 값 도출을 위한 반복 예측 작업 수행\n","threshold_list = []\n","\n","# 0.1부터 0.9 사이 500개의 threshold 후보군을 대상으로 반복 수행\n","for threshold in np.linspace(0.1, 0.9, 500):\n","    y_pred_custom = (y_prob >= threshold).astype(int)\n","    f1 = f1_score(y_test, y_pred_custom)\n","    threshold_list.append((f1, threshold))\n","\n","threshold_list.sort(reverse=True)\n","\n","print('f1-score 기준 상위 5개 threshold 값')\n","\n","for i in range(5):\n","    print(f'{i+1}위: threshold = {threshold_list[i][1]} / f1_score = {threshold_list[i][0]}')"]},{"cell_type":"markdown","metadata":{},"source":["threshold가 0.278 가량일 때 최적의 성능 (f1_score = 0.957)이 도출됨을 알 수 있음."]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      5688\n","           1       1.00      0.92      0.96        48\n","\n","    accuracy                           1.00      5736\n","   macro avg       1.00      0.96      0.98      5736\n","weighted avg       1.00      1.00      1.00      5736\n","\n"]}],"source":["threshold = threshold_list[0][1]\n","\n","y_pred_custom = (y_prob >= threshold).astype(int)\n","\n","class_report = classification_report(y_test, y_pred_custom)\n","print('Classification Report:')\n","print(class_report)"]},{"cell_type":"markdown","metadata":{},"source":["precision 값은 유지시키면서 recall 값을 7% 가량 상승시켰음 => 확연한 성능 개선"]}],"metadata":{"colab":{"provenance":[{"file_id":"1Te6y7zD2MNdN4xxjV965kSzIBcEE938G","timestamp":1705820886881}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
