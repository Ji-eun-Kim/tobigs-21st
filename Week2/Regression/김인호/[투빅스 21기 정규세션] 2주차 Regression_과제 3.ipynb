{"cells":[{"cell_type":"markdown","metadata":{"id":"fu39oBW0RVn5"},"source":["# [과제 3] 로지스틱 회귀분석\n","### - sklearn 패키지를 사용해 로지스틱 회귀분석을 진행해주세요.\n","### - 성능지표를 계산하고 이에 대해 해석해주세요.\n","### - 성능 개선을 시도해주세요. (어떠한 성능지표를 기준으로 개선을 시도했는지, 그 이유도 함께 적어주세요.)\n","### - 주석으로 설명 및 근거 자세하게 달아주시면 감사하겠습니다. :)"]},{"cell_type":"markdown","metadata":{"id":"8rN2SWezRVn_"},"source":["## Data"]},{"cell_type":"markdown","metadata":{"id":"Y7SYKNvQRVn_"},"source":["출처 : https://www.kaggle.com/mlg-ulb/creditcardfraud\n","\n","\n","* V1 ~ V28 : 비식별화 된 개인정보\n","* **Class** : Target 변수  \n","  - 1 : fraudulent transactions (사기)\n","  - 0 : otherwise"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Uvjw2fTCRVoA"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings(action='ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"znQit70ZRVoA"},"outputs":[],"source":["data = pd.read_csv(\"C:/Users/inho0/OneDrive/문서/GitHub/tobigs-21st/Week2/Regression/assignment3_creditcard.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":220},"id":"v98OeXW5RVoB","outputId":"42afeddc-07e6-4224-95ee-08b455f72475"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>V1</th>\n","      <th>V2</th>\n","      <th>V3</th>\n","      <th>V4</th>\n","      <th>V5</th>\n","      <th>V6</th>\n","      <th>V7</th>\n","      <th>V8</th>\n","      <th>V9</th>\n","      <th>V10</th>\n","      <th>...</th>\n","      <th>V20</th>\n","      <th>V21</th>\n","      <th>V22</th>\n","      <th>V23</th>\n","      <th>V24</th>\n","      <th>V25</th>\n","      <th>V26</th>\n","      <th>V27</th>\n","      <th>V28</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-1.848212</td>\n","      <td>2.384900</td>\n","      <td>0.379573</td>\n","      <td>1.048381</td>\n","      <td>-0.845070</td>\n","      <td>2.537837</td>\n","      <td>-4.542983</td>\n","      <td>-10.201458</td>\n","      <td>-1.504967</td>\n","      <td>-2.234167</td>\n","      <td>...</td>\n","      <td>2.585817</td>\n","      <td>-5.291690</td>\n","      <td>0.859364</td>\n","      <td>0.423231</td>\n","      <td>-0.506985</td>\n","      <td>1.020052</td>\n","      <td>-0.627751</td>\n","      <td>-0.017753</td>\n","      <td>0.280982</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2.071805</td>\n","      <td>-0.477943</td>\n","      <td>-1.444444</td>\n","      <td>-0.548657</td>\n","      <td>0.010036</td>\n","      <td>-0.582242</td>\n","      <td>-0.042878</td>\n","      <td>-0.247160</td>\n","      <td>1.171923</td>\n","      <td>-0.342382</td>\n","      <td>...</td>\n","      <td>-0.077306</td>\n","      <td>0.042858</td>\n","      <td>0.390125</td>\n","      <td>0.041569</td>\n","      <td>0.598427</td>\n","      <td>0.098803</td>\n","      <td>0.979686</td>\n","      <td>-0.093244</td>\n","      <td>-0.065615</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-2.985294</td>\n","      <td>-2.747472</td>\n","      <td>1.194068</td>\n","      <td>-0.003036</td>\n","      <td>-1.151041</td>\n","      <td>-0.263559</td>\n","      <td>0.553500</td>\n","      <td>0.635600</td>\n","      <td>0.438545</td>\n","      <td>-1.806488</td>\n","      <td>...</td>\n","      <td>1.345776</td>\n","      <td>0.373760</td>\n","      <td>-0.385777</td>\n","      <td>1.197596</td>\n","      <td>0.407229</td>\n","      <td>0.008013</td>\n","      <td>0.762362</td>\n","      <td>-0.299024</td>\n","      <td>-0.303929</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.479452</td>\n","      <td>1.542874</td>\n","      <td>0.290895</td>\n","      <td>0.838142</td>\n","      <td>-0.529290</td>\n","      <td>-0.717661</td>\n","      <td>0.484516</td>\n","      <td>0.545092</td>\n","      <td>-0.780767</td>\n","      <td>0.324804</td>\n","      <td>...</td>\n","      <td>0.038397</td>\n","      <td>0.116771</td>\n","      <td>0.405560</td>\n","      <td>-0.116453</td>\n","      <td>0.541275</td>\n","      <td>-0.216665</td>\n","      <td>-0.415578</td>\n","      <td>0.027126</td>\n","      <td>-0.150347</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.281976</td>\n","      <td>-0.309699</td>\n","      <td>-2.162299</td>\n","      <td>-0.851514</td>\n","      <td>0.106167</td>\n","      <td>-1.483888</td>\n","      <td>1.930994</td>\n","      <td>-0.843049</td>\n","      <td>-1.249272</td>\n","      <td>1.079608</td>\n","      <td>...</td>\n","      <td>-0.875516</td>\n","      <td>-0.004199</td>\n","      <td>1.015108</td>\n","      <td>-0.026748</td>\n","      <td>0.077115</td>\n","      <td>-1.468822</td>\n","      <td>0.751700</td>\n","      <td>0.496732</td>\n","      <td>0.331001</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 29 columns</p>\n","</div>"],"text/plain":["         V1        V2        V3        V4        V5        V6        V7  \\\n","0 -1.848212  2.384900  0.379573  1.048381 -0.845070  2.537837 -4.542983   \n","1  2.071805 -0.477943 -1.444444 -0.548657  0.010036 -0.582242 -0.042878   \n","2 -2.985294 -2.747472  1.194068 -0.003036 -1.151041 -0.263559  0.553500   \n","3 -1.479452  1.542874  0.290895  0.838142 -0.529290 -0.717661  0.484516   \n","4 -0.281976 -0.309699 -2.162299 -0.851514  0.106167 -1.483888  1.930994   \n","\n","          V8        V9       V10  ...       V20       V21       V22       V23  \\\n","0 -10.201458 -1.504967 -2.234167  ...  2.585817 -5.291690  0.859364  0.423231   \n","1  -0.247160  1.171923 -0.342382  ... -0.077306  0.042858  0.390125  0.041569   \n","2   0.635600  0.438545 -1.806488  ...  1.345776  0.373760 -0.385777  1.197596   \n","3   0.545092 -0.780767  0.324804  ...  0.038397  0.116771  0.405560 -0.116453   \n","4  -0.843049 -1.249272  1.079608  ... -0.875516 -0.004199  1.015108 -0.026748   \n","\n","        V24       V25       V26       V27       V28  Class  \n","0 -0.506985  1.020052 -0.627751 -0.017753  0.280982      0  \n","1  0.598427  0.098803  0.979686 -0.093244 -0.065615      0  \n","2  0.407229  0.008013  0.762362 -0.299024 -0.303929      0  \n","3  0.541275 -0.216665 -0.415578  0.027126 -0.150347      0  \n","4  0.077115 -1.468822  0.751700  0.496732  0.331001      0  \n","\n","[5 rows x 29 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["data.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix: \n","[[5685    1]\n"," [   9   41]]\n","Classification Report: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00      5686\n","           1       0.98      0.82      0.89        50\n","\n","    accuracy                           1.00      5736\n","   macro avg       0.99      0.91      0.95      5736\n","weighted avg       1.00      1.00      1.00      5736\n","\n","ROC AUC Score:  0.9099120647203658\n"]}],"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n","\n","\n","# 독립변수와 종속변수 분리\n","X = data.iloc[:, :-1]\n","y = data['Class']\n","\n","# 학습 데이터와 테스트 데이터 분리\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2024)\n","\n","# 기본 모델로 로지스틱 회귀 모델 학습\n","model = LogisticRegression()\n","model.fit(X_train, y_train)\n","\n","# 예측\n","y_pred = model.predict(X_test)\n","\n","# 성능 평가\n","print(\"Confusion Matrix: \")\n","print(confusion_matrix(y_test, y_pred))\n","print(\"Classification Report: \")\n","print(classification_report(y_test, y_pred))\n","print(\"ROC AUC Score: \", roc_auc_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ROC AUC Score:  0.9099120647203658"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix: \n","[[5531  155]\n"," [   3   47]]\n","Classification Report: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99      5686\n","           1       0.23      0.94      0.37        50\n","\n","    accuracy                           0.97      5736\n","   macro avg       0.62      0.96      0.68      5736\n","weighted avg       0.99      0.97      0.98      5736\n","\n","ROC AUC Score:  0.9563700316567008\n"]}],"source":["# SMOTE를 사용하여 소수 클래스의 데이터를 증가시켜 클래스 불균형 문제를 해결\n","from imblearn.over_sampling import SMOTE\n","\n","# 오버샘플링\n","smote = SMOTE(random_state=2024)\n","X_smote, y_smote = smote.fit_resample(X_train, y_train)\n","\n","# 로지스틱 회귀 모델 학습\n","model = LogisticRegression()\n","model.fit(X_smote, y_smote)\n","\n","# 예측 및 성능 평가\n","y_pred = model.predict(X_test)\n","print(\"Confusion Matrix: \")\n","print(confusion_matrix(y_test, y_pred))\n","print(\"Classification Report: \")\n","print(classification_report(y_test, y_pred))\n","print(\"ROC AUC Score: \", roc_auc_score(y_test, y_pred))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ROC AUC Score:  0.9563700316567008\n","# 사기 거래를 놓치는 것이 일반 거래를 사기로 잘못 분류하는 것보다 더 큰 문제가 될 수 있어서 재현율( 실제 Positive인 것 중에서 모델이 Positive라고 예측한 비율)을 높이는 것 중요\n","# -> 임계값 조정 방식 고려하기\n","\n","# y_pred_proba = model.predict_proba(X_test)\n","# threshold = 0.7\n","# y_pred = (y_pred_proba[:,1] >= threshold).astype('int')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Confusion Matrix: \n","[[5540  146]\n"," [   3   47]]\n","Classification Report: \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.99      5686\n","           1       0.24      0.94      0.39        50\n","\n","    accuracy                           0.97      5736\n","   macro avg       0.62      0.96      0.69      5736\n","weighted avg       0.99      0.97      0.98      5736\n","\n","ROC AUC Score:  0.9571614491734084\n"]}],"source":["# 파라미터 개선\n","\n","model = LogisticRegression(penalty='l2', C=0.1, class_weight='balanced')\n","\n","# penalty: 규제의 종류를 설정합니다. \n","# C: C 값이 작을수록 규제 강도가 크다.\n","# class_weight: 클래스의 가중치를 설정한다. 불균형 데이터셋을 다룰 때 유용하다. balanced를 설정시 클래스의 빈도에 반비례하게 가중치를 자동으로 조정\n","model.fit(X_smote, y_smote)\n","\n","y_pred = model.predict(X_test)\n","print(\"Confusion Matrix: \")\n","print(confusion_matrix(y_test, y_pred))\n","print(\"Classification Report: \")\n","print(classification_report(y_test, y_pred))\n","print(\"ROC AUC Score: \", roc_auc_score(y_test, y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# ROC AUC Score:  0.9571614491734084 (약하게 개선, 불균형률 개선이 유의미하다.)"]}],"metadata":{"colab":{"provenance":[{"file_id":"1Te6y7zD2MNdN4xxjV965kSzIBcEE938G","timestamp":1705820886881}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
